## Intelligence Artificielle (IA), Machine Learning, Deep Learning & NLP - Q/A

### Q1: Quelle est la différence entre IA, Machine Learning et Deep Learning ?
**Réponse:**
L'IA est le domaine général visant à créer des systèmes capables d'effectuer des tâches intelligentes. Le Machine Learning est une sous-catégorie de l'IA où les modèles apprennent à partir de données. Le Deep Learning est une branche du ML utilisant des réseaux de neurones profonds pour traiter des données complexes.

### Q2: Expliquez le sur-apprentissage (overfitting) et comment le prévenir.
**Réponse:**
Le sur-apprentissage se produit quand un modèle apprend trop bien les détails du jeu de données d'entraînement, au détriment de sa capacité à généraliser. On peut le prévenir par la régularisation, la validation croisée, l'augmentation des données, ou l'arrêt précoce.

### Q3: Qu'est-ce qu'un réseau de neurones convolutionnel (CNN) ?
**Réponse:**
Un CNN est un type de réseau de neurones utilisé principalement pour le traitement d'images. Il utilise des couches de convolution pour extraire des caractéristiques locales.

### Q4: Qu'est-ce que le NLP et citez des tâches courantes ?
**Réponse:**
Le NLP (Natural Language Processing) est le traitement automatique du langage naturel. Tâches courantes : classification de texte, analyse de sentiment, traduction automatique, génération de texte, question-réponse.

### Q5: Expliquez le concept de word embeddings.
**Réponse:**
Les word embeddings sont des représentations vectorielles de mots qui capturent leur signification sémantique. Exemples : Word2Vec, GloVe, FastText.




**Q: Difference between AI, ML, and DL?**  
- **AI**: Broad field for building intelligent systems.  
- **ML**: Subset of AI, models learn patterns from data.  
- **DL**: Subset of ML using deep neural networks.

**Q: Types of ML?**  
- **Supervised**: Trained on labeled data.  
- **Unsupervised**: Finds structure in unlabeled data.  
- **Reinforcement Learning**: Learns from feedback in an environment.

**Q: Key challenges in NLP?**  
- Ambiguity, context understanding, long-term dependencies, bias in data.

**Q: What are Transformers?**  
- Architecture introduced in *Attention is All You Need (2017)*.  
- Uses attention mechanisms to handle long dependencies efficiently.  
- Basis of modern LLMs.
